- Microservice Pattern      
    - API gateway pattern
    - Service Registery and Discorver 
    - Circuit Breaker 
    - Loose coupling
    - Database per service 
    - CQRS

### Bias Detection:
Bias in AI can lead to unfair, discriminatory outcomes that can exacerbate existing social inequalities.
Bias Detection can be done using:
- pre-processing tools
- in-processing tools
- post-processing tools

Prominent Bias Detection Tools
* AI Fairness 360 (AIF360) : IBM
* Fairness Indicators : Google
* Fairlearn: Microsoft
* Themis-ML
* What-If Tool

Current issues with bias detection:
* Bias is a complex and multifaceted issue, making it difficult to detect and mitigate entirely.
* As data evolves, new biases can emerge, requiring continuous monitoring and adjustment.
* There are often trade-offs between fairness and other performance metrics, necessitating careful consideration and balance.

Bias Detection Factors:
* Validity: The method should measure what it intends to measure and capture the relevant aspects of bias in LLM outputs.
* Reliability: The method should produce consistent and reproducible results across different settings and scenarios.
* Fairness: The method should not introduce or amplify any new or existing biases in the measurement process or outcomes.
* Transparency: The method should be clear and explainable about its assumptions, limitations, and implications.
* Accountability: The method should be responsible and ethical about its use and impact on the users and society.